{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  To identify and correct grammatical errors.\n",
    "\n",
    "Reference code by By Sunil Chomal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "    0.1) Pre-procecssing\n",
    "    1) Tokenization\n",
    "    2) Part of Speech Tagging\n",
    "    3) Entity Detectors\n",
    "    4) Dependency Parsing\n",
    "    5) Noun Phrases\n",
    "    6) Word to Vector Integration\n",
    "    7) Machine Learning with Text (SpaCy)\n",
    "    \n",
    "We will not follow these steps as we are using BERT which is pretrained model. New steps to follow are listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Tokenization with Spacy\n",
    "\n",
    "2.Spelling erros with Textblob or Hunspell\n",
    "\n",
    "3.Create set of probable sentences\n",
    "\n",
    "4.Create a set of sentences with each word “masked” (deleted or an additional determiner, preposition or helper verb added)\n",
    "\n",
    "5.Create probable suggestions for masks using Bert Masked Language Model\n",
    "\n",
    "6.GED model to select best suggestion (Generalized Error Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries \n",
    "\n",
    "# pytorch_pretrained_bert\n",
    "#!pip install -U pytorch_pretrained_bert \n",
    "\n",
    "#Pytorch\n",
    "#!pip install torch\n",
    "\n",
    "# Keras\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "GPU device not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-290cf4c7de84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'GPU device not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Found GPU at: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: GPU device not found"
     ]
    }
   ],
   "source": [
    "# Check to confirm that GPU is available\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError ('GPU device not found')\n",
    "\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can not figure out how to use GPU so will work on CPU only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 231508/231508 [00:02<00:00, 90262.59B/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries required\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_GE(sents):\n",
    "    \"\"\"Check of the input sentences have grammatical errors\n",
    "    :param list: list of sentences\n",
    "    :return: error, probabilities\n",
    "    :rtype: (boolean, (float, float))\n",
    "    \"\"\"\n",
    "    \n",
    "# Create sentence) and label lists\n",
    "# We need to add special tokens at the beginning and end of each sentence\n",
    "# for BERT to work properly\n",
    "    sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sents]\n",
    "    labels =[0]\n",
    "\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # Padding Sentences\n",
    "    # Set the maximum sequence length. The longest sequence in our training set\n",
    "    # is 47, but we'll leave room on the end anyway.\n",
    "    # In the original paper, the authors used a length of 512.\n",
    "    MAX_LEN = 128\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "  # Pad our input tokens\n",
    "    input_ids = pad_sequences(\n",
    "        [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts], \n",
    "        maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\"\n",
    "        )\n",
    "\n",
    "  # Index Numbers and Padding\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "  # pad sentences\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                            dtype =\"long\", truncating=\"post\",padding =\"post\")\n",
    "\n",
    "  # Attention masks\n",
    "  # Create attention masks\n",
    "    attention_masks = []\n",
    "\n",
    "  # Create a mask of 1s for each token followed by 0s for padding\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i > 0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    prediction_inputs = torch.tensor(input_ids).to(torch.int64)\n",
    "    prediction_masks = torch.tensor(attention_masks)\n",
    "    prediction_labels = torch.tensor(labels)\n",
    "   \n",
    "    with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "        logits = modelGED(prediction_inputs, token_type_ids=None, \n",
    "                      attention_mask=prediction_masks)\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "  # label_ids = b_labels.to(\"cpu\").numpy()\n",
    "\n",
    "  # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "  # true_labels.append(label_ids)\n",
    "\n",
    "#   print(predictions)\n",
    "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "#   print(flat_predictions)\n",
    "    prob_vals = flat_predictions\n",
    "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "  # flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "#   print(flat_predictions)\n",
    "    return flat_predictions, prob_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "  print(\"Trying to fetch {}\".format(destination))\n",
    "\n",
    "  def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "      if key.startswith('download_warning'):\n",
    "        return value\n",
    "\n",
    "    return None\n",
    "\n",
    "  def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "      for chunk in progress_bar(response.iter_content(CHUNK_SIZE)):\n",
    "        if chunk: # filter out keep-alive new chunks\n",
    "          f.write(chunk)\n",
    "\n",
    "  URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "  session = requests.Session()\n",
    "\n",
    "  response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "  token = get_confirm_token(response)\n",
    "\n",
    "  if token:\n",
    "    params = { 'id' : id, 'confirm' : token }\n",
    "    response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "  save_response_content(response, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(some_iter):\n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "        return tqdm(some_iter)\n",
    "    except ModuleNotFoundError:\n",
    "        return some_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pretrained BERT Grammer Error Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to fetch ./bert-based-uncased-GED.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13367it [05:58, 37.33it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# download from public google drive link\n",
    "download_file_from_google_drive(\"1al7v87aRxebSUCXrN2Sdd0jGUS0zZ3vn\", \"./bert-based-uncased-GED.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertForSequenceClassification\n",
    "\n",
    "modelGED = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                      num_labels=2)\n",
    "\n",
    "# restore model\n",
    "modelGED.load_state_dict(torch.load('bert-based-uncased-GED.pth',map_location=torch.device('cpu')))\n",
    "modelGED.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 1248501532/1248501532 [1:45:44<00:00, 196784.01B/s]\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=1024, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 231508/231508 [00:00<00:00, 315012.17B/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizerLarge = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cyhunspell in c:\\users\\nik8p\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: cacheman>=2.0.6 in c:\\users\\nik8p\\anaconda3\\lib\\site-packages (from cyhunspell) (2.1.0)\n",
      "Requirement already satisfied: future>=0.16.0 in c:\\users\\nik8p\\anaconda3\\lib\\site-packages (from cacheman>=2.0.6->cyhunspell) (0.18.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\nik8p\\anaconda3\\lib\\site-packages (from cacheman>=2.0.6->cyhunspell) (1.15.0)\n",
      "Requirement already satisfied: psutil>=2.1.0 in c:\\users\\nik8p\\anaconda3\\lib\\site-packages (from cacheman>=2.0.6->cyhunspell) (5.8.0)\n"
     ]
    }
   ],
   "source": [
    "# install the packages for Hunspell\n",
    "\n",
    "!pip install cyhunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - libhunspell-dev\n",
      "  - libhunspell-1.6-0\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n"
     ]
    }
   ],
   "source": [
    "!conda install libhunspell-1.6-0 libhunspell-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to fetch ./en_GB-large.dic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:00, 38.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to fetch ./en_GB-large.aff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 1048.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from hunspell import Hunspell\n",
    "import os\n",
    "\n",
    "# download the gn_GB dictionary for hunspell\n",
    "download_file_from_google_drive(\"1jC5BVF9iZ0gmRQNmDcZnhfFdEYv8RNok\", \"./en_GB-large.dic\")\n",
    "download_file_from_google_drive(\"1g8PO8kdw-YmyOY_HxjnJ5FfdJFX4bsPv\", \"./en_GB-large.aff\")\n",
    "\n",
    "gb = Hunspell(\"en_GB-large\", hunspell_data_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of common determiners\n",
    "# det = [\"\", \"the\", \"a\", \"an\"]\n",
    "det = ['the', 'a', 'an', 'this', 'that', 'these', 'those', 'my', 'your', 'his', \n",
    "       'her', 'its', 'our', 'their', 'all', 'both', 'half', 'either', 'neither', \n",
    "       'each', 'every', 'other', 'another', 'such', 'what', 'rather', 'quite']\n",
    "\n",
    "# List of common prepositions\n",
    "prep = [\"about\", \"at\", \"by\", \"for\", \"from\", \"in\", \"of\", \"on\", \"to\", \"with\", \n",
    "        \"into\", \"during\", \"including\", \"until\", \"against\", \"among\", \n",
    "        \"throughout\", \"despite\", \"towards\", \"upon\", \"concerning\"]\n",
    "\n",
    "# List of helping verbs\n",
    "helping_verbs = ['am', 'is', 'are', 'was', 'were', 'being', 'been', 'be', \n",
    "                 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', \n",
    "                 'shall', 'should', 'may', 'might', 'must', 'can', 'could']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sentences\n",
    "\n",
    "org_text = []\n",
    "org_text.append(\"I am gone to home .\")\n",
    "org_text.append(\"I was completing Intership project .\")\n",
    "org_text.append(\"All a light we cannot see .\")\n",
    "org_text.append(\"We where talking .\")\n",
    "org_text.append('There is no a problem, we can the do whatyou ask .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import en_core_web_sm\n",
    "def create_spelling_set(org_text):\n",
    "  \"\"\" Create a set of sentences which have possible corrected spellings\n",
    "  \"\"\"\n",
    "  \n",
    "  sent = org_text\n",
    "  sent = sent.lower()\n",
    "  sent = sent.strip().split()\n",
    "\n",
    "\n",
    "\n",
    "  nlp = en_core_web_sm.load()\n",
    "  proc_sent = nlp.tokenizer.tokens_from_list(sent)\n",
    "  nlp.tagger(proc_sent)\n",
    "\n",
    "  sentences = []\n",
    "\n",
    "  for tok in proc_sent:\n",
    "    # check for spelling for alphanumeric\n",
    "    if tok.text.isalpha() and not gb.spell(tok.text):\n",
    "      new_sent = sent[:]\n",
    "      # append new sentences with possible corrections\n",
    "      for sugg in gb.suggest(tok.text):\n",
    "        new_sent[tok.i] = sugg\n",
    "        sentences.append(\" \".join(new_sent))\n",
    "\n",
    "  spelling_sentences = sentences\n",
    "\n",
    "  # retain new sentences which have a \n",
    "  # minimum chance of correctness using BERT GED\n",
    "  new_sentences = []\n",
    "  \n",
    "  for sent in spelling_sentences:\n",
    "    no_error, prob_val = check_GE([sent])\n",
    "    exps = [np.exp(i) for i in prob_val[0]]\n",
    "    sum_of_exps = sum(exps)\n",
    "    softmax = [j/sum_of_exps for j in exps]\n",
    "    if(softmax[1] > 0.6):\n",
    "      new_sentences.append(sent)\n",
    "  \n",
    "  \n",
    "  # if no corrections, append the original sentence\n",
    "  if len(spelling_sentences) == 0:\n",
    "    spelling_sentences.append(\" \".join(sent))\n",
    "\n",
    "  # eliminate dupllicates\n",
    "  [spelling_sentences.append(sent) for sent in new_sentences]\n",
    "  spelling_sentences = list(dict.fromkeys(spelling_sentences))\n",
    "\n",
    "  return spelling_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar_set(spelling_sentences):\n",
    "  \"\"\" create a new set of sentences with deleted determiners, \n",
    "      prepositions & helping verbs\n",
    "      \n",
    "  \"\"\"\n",
    "  \n",
    "  new_sentences = []\n",
    "\n",
    "  for text in spelling_sentences:\n",
    "    sent = text.strip().split()\n",
    "    for i in range(len(sent)):\n",
    "      new_sent = sent[:]\n",
    "      \n",
    "      if new_sent[i] not in list(set(det + prep + helping_verbs)):\n",
    "        continue\n",
    "      \n",
    "      del new_sent[i]\n",
    "      text = \" \".join(new_sent)\n",
    "      \n",
    "      # retain new sentences which have a \n",
    "      # minimum chance of correctness using BERT GED\n",
    "      no_error, prob_val = check_GE([text])\n",
    "      exps = [np.exp(i) for i in prob_val[0]]\n",
    "      sum_of_exps = sum(exps)\n",
    "      softmax = [j/sum_of_exps for j in exps]\n",
    "      if(softmax[1] > 0.6):\n",
    "        new_sentences.append(text)\n",
    "  \n",
    "  # eliminate dupllicates\n",
    "  [spelling_sentences.append(sent) for sent in new_sentences]\n",
    "  spelling_sentences = list(dict.fromkeys(spelling_sentences))\n",
    "  return spelling_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_set(spelling_sentences):\n",
    "  \"\"\"For each input sentence create 2 sentences\n",
    "     (1) [MASK] each word\n",
    "     (2) [MASK] for each space between words\n",
    "  \"\"\"\n",
    "  sentences = []\n",
    "\n",
    "  for sent in spelling_sentences:\n",
    "    sent = sent.strip().split()\n",
    "    for i in range(len(sent)):\n",
    "      # (1) [MASK] each word\n",
    "      new_sent = sent[:]\n",
    "      new_sent[i] = '[MASK]'\n",
    "      text = \" \".join(new_sent)\n",
    "      new_sent = '[CLS] ' + text + ' [SEP]'\n",
    "      sentences.append(new_sent)\n",
    "\n",
    "      # (2) [MASK] for each space between words\n",
    "      new_sent = sent[:]\n",
    "      new_sent.insert(i, '[MASK]')\n",
    "      text = \" \".join(new_sent)\n",
    "      new_sent = '[CLS] ' + text + ' [SEP]'\n",
    "      sentences.append(new_sent)\n",
    "\n",
    "  return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def check_grammar(org_sent, sentences, spelling_sentences):\n",
    "  \"\"\" check grammar for the input sentences\n",
    "  \"\"\"\n",
    "  \n",
    "  n = len(sentences)\n",
    "  \n",
    "  # what is the tokenized value of [MASK]. Usually 103\n",
    "  text = '[MASK]'\n",
    "  tokenized_text = tokenizerLarge.tokenize(text)\n",
    "  mask_token = tokenizerLarge.convert_tokens_to_ids(tokenized_text)[0]\n",
    "\n",
    "  LM_sentences = []\n",
    "  new_sentences = []\n",
    "  i = 0 # current sentence number\n",
    "  l = len(org_sent.strip().split())*2 # l is no of sentencees\n",
    "  mask = False # flag indicating if we are processing space MASK\n",
    "\n",
    "  for sent in sentences:\n",
    "    i += 1\n",
    "    \n",
    "    print(\".\", end=\"\")\n",
    "    if i%50 == 0:\n",
    "      print(\"\")\n",
    "    \n",
    "    # tokenize the text\n",
    "    tokenized_text = tokenizerLarge.tokenize(sent)\n",
    "    indexed_tokens = tokenizerLarge.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Create the segments tensors.\n",
    "    segments_ids = [0] * len(tokenized_text)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # Predict all tokens\n",
    "    with torch.no_grad():\n",
    "        predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # index of the masked token\n",
    "    mask_index = (tokens_tensor == mask_token).nonzero()[0][1].item()\n",
    "    # predicted token\n",
    "    predicted_index = torch.argmax(predictions[0, mask_index]).item()\n",
    "    predicted_token = tokenizerLarge.convert_ids_to_tokens([predicted_index])[0]\n",
    "    \n",
    "    # second best prediction. Can you used to create more options\n",
    "#     second_index = torch.topk(predictions[0, mask_index], 2).indices[1].item()\n",
    "#     second_prediction = tokenizer.convert_ids_to_tokens([second_index])[0]\n",
    "\n",
    "    text = sent.strip().split()\n",
    "    mask_index = text.index('[MASK]')\n",
    "\n",
    "    if not mask:\n",
    "      # case of MASKed words\n",
    "      \n",
    "      mask = True\n",
    "      text[mask_index] = predicted_token\n",
    "      try:\n",
    "        # retrieve original word\n",
    "        org_word = spelling_sentences[i//l].strip().split()[mask_index-1]\n",
    "#         print(\">>> \" + org_word)\n",
    "      except:\n",
    "#         print(spelling_sentences[i%l - 1])\n",
    "#         print(tokenized_text)\n",
    "#         print(\"{0} {1} {2}\".format(i, l, mask_index))\n",
    "        print(\"!\", end=\"\")\n",
    "        continue\n",
    "  #     print(\"{0} - {1}\".format(org_word, predicted_token))\n",
    "      # check if the prediction is an inflection of the original word\n",
    "  #   if org_word.isalpha() and predicted_token not in gb_infl[org_word]:\n",
    "  #     continue\n",
    "      # use SequenceMatcher to see if predicted word is similar to original word\n",
    "      if SequenceMatcher(None, org_word, predicted_token).ratio() < 0.6:\n",
    "        if org_word not in list(set(det + prep + helping_verbs)) or predicted_token not in list(set(det + prep + helping_verbs)):\n",
    "          continue\n",
    "      if org_word == predicted_token:\n",
    "        continue\n",
    "    else:\n",
    "      # case for MASKed spaces\n",
    "      \n",
    "      mask = False\n",
    "  #     print(\"{0}\".format(predicted_token))\n",
    "      # only allow determiners / prepositions  / helping verbs in spaces\n",
    "      if predicted_token in list(set(det + prep + helping_verbs)) :\n",
    "        text[mask_index] = predicted_token\n",
    "      else:\n",
    "        continue\n",
    "\n",
    "  #   if org_word == \"in\":\n",
    "  #     print(\">>>>>> \" + predicted_token)\n",
    "  #   print(tokenized_text)\n",
    "  #   print(mask_index)\n",
    "  \n",
    "    text.remove('[SEP]')\n",
    "    text.remove('[CLS]')\n",
    "    new_sent = \" \".join(text)\n",
    "    \n",
    "  #   print(new_sent)\n",
    "    # retain new sentences which have a \n",
    "    # minimum chance of correctness using BERT GED\n",
    "    no_error, prob_val = check_GE([new_sent])\n",
    "    exps = [np.exp(i) for i in prob_val[0]]\n",
    "    sum_of_exps = sum(exps)\n",
    "    softmax = [j/sum_of_exps for j in exps]\n",
    "    if no_error and softmax[1] > 0.996:\n",
    "  #     print(org_word)\n",
    "  #     print(predicted_token)\n",
    "  #     print(SequenceMatcher(None, org_word, predicted_token).ratio())\n",
    "  #     print(\"{0} - {1}, {2}\".format(prob_val[0][1], prob_val[0][0], prob_val[0][1] - prob_val[0][0]))\n",
    "\n",
    "  #     print(\"{0} - {1:.2f}\".format(new_sent, softmax[1]*100) )\n",
    "      print(\"*\", end=\"\")\n",
    "      new_sentences.append(new_sent)\n",
    "  #   print(\"{0}\\t{1}\".format(predicted_token, second_prediction))\n",
    "\n",
    "  print(\"\")\n",
    "  \n",
    "  # remove duplicate suggestions\n",
    "  spelling_sentences = []\n",
    "  [spelling_sentences.append(sent) for sent in new_sentences]\n",
    "  spelling_sentences = list(dict.fromkeys(spelling_sentences))\n",
    "  spelling_sentences\n",
    "  \n",
    "  return spelling_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence >>> I am gone to home .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nik8p\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: [W002] Tokenizer.from_list is now deprecated. Create a new Doc object instead and pass in the strings as the `words` keyword argument, for example:\n",
      "from spacy.tokens import Doc\n",
      "doc = Doc(nlp.vocab, words=[...])\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 22 possibilities\n",
      "...*.......*.....*..*.....\n",
      "Suggestions & Probabilities\n",
      "i had gone to home . - 99.6320%\n",
      "i am gone to my home . - 99.7258%\n",
      "i had gone home . - 99.8374%\n",
      "i am going home . - 99.8354%\n",
      "------------------------------------------------------------\n",
      "\n",
      "Input Sentence >>> I was completing Intership project .\n",
      "processing 88 possibilities\n",
      "........*.................!.........*................\n",
      ".!.........*............*............*.!..!.\n",
      "Suggestions & Probabilities\n",
      "i was completing my internship project . - 99.8190%\n",
      "i was completing the inter-ship project . - 99.7580%\n",
      "i was completing the inters-hip project . - 99.7807%\n",
      "i was completing the interneship project . - 99.8161%\n",
      "i was completing the intersperse project . - 99.8367%\n",
      "------------------------------------------------------------\n",
      "\n",
      "Input Sentence >>> All a light we cannot see .\n",
      "processing 26 possibilities\n",
      "....................*.*.....\n",
      "Suggestions & Probabilities\n",
      "a light that we cannot see . - 99.8193%\n",
      "a light we can see . - 99.8222%\n",
      "------------------------------------------------------------\n",
      "\n",
      "Input Sentence >>> We where talking .\n",
      "processing 8 possibilities\n",
      "...*.....\n",
      "Suggestions & Probabilities\n",
      "we were talking . - 99.8261%\n",
      "------------------------------------------------------------\n",
      "\n",
      "Input Sentence >>> There is no a problem, we can the do whatyou ask .\n",
      "processing 98 possibilities\n",
      ".........................!.........................\n",
      ".....................................*..........!.\n",
      "Suggestions & Probabilities\n",
      "there is no a problem, we will do what you ask . - 99.6245%\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# org_text = []\n",
    "# with open(\"./drive/My Drive/Colab Notebooks/S89A/CoNLL_2013_DS.txt\") as file:\n",
    "#   org_text = file.readlines()\n",
    "\n",
    "# predict for each of the test samples\n",
    "\n",
    "for sent in org_text:\n",
    "  \n",
    "  print(\"Input Sentence >>> \" + sent)\n",
    "  \n",
    "  sentences = create_spelling_set(sent)\n",
    "  spelling_sentences = create_grammar_set(sentences)\n",
    "  sentences = create_mask_set(spelling_sentences)\n",
    "  \n",
    "  print(\"processing {0} possibilities\".format(len(sentences)))\n",
    "  \n",
    "  sentences = check_grammar(sent, sentences, spelling_sentences)\n",
    "\n",
    "  print(\"Suggestions & Probabilities\")\n",
    "  \n",
    "  if len(sentences) == 0:\n",
    "    print(\"None\")\n",
    "    continue\n",
    "\n",
    "  no_error, prob_val =  check_GE(sentences)\n",
    "\n",
    "  for i in range(len(prob_val)):\n",
    "    exps = [np.exp(i) for i in prob_val[i]]\n",
    "    sum_of_exps = sum(exps)\n",
    "    softmax = [j/sum_of_exps for j in exps]\n",
    "    print(\"{0} - {1:0.4f}%\".format(sentences[i], softmax[1]*100))\n",
    "  \n",
    "  print(\"-\"*60)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
